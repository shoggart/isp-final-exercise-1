{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0930cf4",
   "metadata": {},
   "source": [
    "Use pip to install the OpenCV software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a75ca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe0afc",
   "metadata": {},
   "source": [
    "Use pip to install the NumPy software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c077fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (1.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a22ea",
   "metadata": {},
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e1f34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29442904",
   "metadata": {},
   "source": [
    "This function accepts a path to a video. It then uses the OpenCV software to randomly collect\n",
    "50 frames from the video and then finds the median of those 50 frames. This median will be used\n",
    "for background subtraction in order to detect motion within the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbea54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_background(path):\n",
    "    #open video from a given path\n",
    "    video = cv2.VideoCapture(path)\n",
    "    # use 50 random frames for median\n",
    "    indexes = video.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=50)\n",
    "    # an array to hold the frames\n",
    "    frames = []\n",
    "    \n",
    "    for i in indexes:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        check, frame = video.read()\n",
    "        frames.append(frame)\n",
    "        \n",
    "    # use numpy median function to calculate median of 50 random frames\n",
    "    med_frame = np.median(frames, axis=0).astype(np.uint8)\n",
    "    return med_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde37c9",
   "metadata": {},
   "source": [
    "This is the meat and potatoes of the application. It's the function where all the frame \n",
    "differencing occurs. It accepts a path to the required video which it sends to \n",
    "median_background to find a median frame. The function then converts this background frame \n",
    "to gray scale and uses the difference of this with the grayscale converted frames of the\n",
    "video to determine if motion is taking place. Since we're dealing with the detection of cars\n",
    "here it only draws green rectangles around objects with areas above a certain threshold so\n",
    "as not to draw rectangles around people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa20fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frameDifferencing(path, numframes, rect_loc):\n",
    "    video = cv2.VideoCapture(path)\n",
    "\n",
    "    #height of the frame used to only detect cars on main street\n",
    "    height = int(video.get(4))\n",
    "\n",
    "    # get median background\n",
    "    background = median_background(path)\n",
    "    # convert to grayscale\n",
    "    background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "    count = 0\n",
    "    num_frames = numframes\n",
    "\n",
    "    city_center = 0\n",
    "    curr_rect = []\n",
    "    prev_rect = []\n",
    "    while (video.isOpened()):\n",
    "        check, frame = video.read()\n",
    "        if check == True:\n",
    "            count += 1\n",
    "            # make copy of original frame\n",
    "            original_frame = frame.copy()\n",
    "            # convert frame to grayscale\n",
    "            gray_scale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            # checks whether frame count has reached a multiple of num_frames \n",
    "            if count % num_frames == 0 or count == 1:\n",
    "                diff_arr = []\n",
    "            # calculates absolute difference between gray scale and background\n",
    "            abs_diff = cv2.absdiff(gray_scale, background)\n",
    "            # converts the difference to binary using thresholding\n",
    "            check, thres = cv2.threshold(abs_diff, 50, 255, cv2.THRESH_BINARY)\n",
    "            # dilate frame to increase contour detection\n",
    "            dil_frame = cv2.dilate(thres, None, iterations=2)\n",
    "            # append the final result into the `diff_arr`\n",
    "            diff_arr.append(dil_frame)\n",
    "            # check if diff_arr has reached the required length\n",
    "            if len(diff_arr) == num_frames:\n",
    "                # sum the frames in diff_arr\n",
    "                sum_num_frames = sum(diff_arr)\n",
    "                # save contours around the white dilated areas\n",
    "                contours, hierarchy = cv2.findContours(sum_num_frames, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                for i in range(len(contours)):\n",
    "                    # move past contours with area less than 500 to\n",
    "                    # filter out noise\n",
    "                    if cv2.contourArea(contours[i]) < 500:\n",
    "                        continue\n",
    "                    (x, y, w, h) = cv2.boundingRect(contours[i])\n",
    "\n",
    "\n",
    "                    # draw green rectangles\n",
    "                    if y > height / 2 and w * h > 6000:\n",
    "                        cv2.rectangle(original_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                        curr_rect.append((x, y, w, h))\n",
    "\n",
    "                # find the minimum length of the previous and current\n",
    "                # array of rectangles\n",
    "                min_len = min(len(curr_rect), len(prev_rect))\n",
    "                for i in range(min_len):\n",
    "                    if curr_rect[i][0] > 400 and curr_rect[i][0] < rect_loc and curr_rect[i][1] > 350 and curr_rect[i][1] < 400 and curr_rect[i][0] < prev_rect[i][0]:\n",
    "                        # count number of cars going towards city center\n",
    "                        # and print current value\n",
    "                        city_center += 1\n",
    "                        print(city_center)\n",
    "\n",
    "                # set previous array of rectangles equal to current array of rectangles\n",
    "                prev_rect = curr_rect\n",
    "                # reset current array of rectangles\n",
    "                curr_rect = []\n",
    "\n",
    "                cv2.imshow('Detected Objects', original_frame)\n",
    "                if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows() \n",
    "    return city_center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daeda58",
   "metadata": {},
   "source": [
    "Call the frame differencing function for both the recordings from the city traffic cameras. \n",
    "Store the traffic data of cars heading to the city center in two separate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd0f5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "city_center1 = frameDifferencing('Exercise1_Files/Traffic_Laramie_1.mp4', 4, 435)\n",
    "city_center2 = frameDifferencing('Exercise1_Files/Traffic_Laramie_2.mp4', 5, 440)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c46ed0",
   "metadata": {},
   "source": [
    "Use pip to install the moviepy package used to extract the lengths of each of the traffic recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb2cdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (1.0.3)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (4.62.3)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (0.1.9)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (1.20.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (0.4.5)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from moviepy) (2.26.0)\n",
      "Requirement already satisfied: pillow in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.8.1->moviepy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/spencer/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install moviepy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94288cd5",
   "metadata": {},
   "source": [
    "Import the necessary packages from moviepy and use it to extract and print the video lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08adcca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.92000000000002\n",
      "105.68\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "clip1 = VideoFileClip('Exercise1_Files/Traffic_Laramie_1.mp4')\n",
    "print(clip1.duration)\n",
    "clip2 = VideoFileClip('Exercise1_Files/Traffic_Laramie_2.mp4')\n",
    "print(clip2.duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6742a6de",
   "metadata": {},
   "source": [
    "Divide the clip durations by 60 to convert the lengths to minutes instead of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09a8cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "length1 = clip1.duration / 60\n",
    "length2 = clip2.duration / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f2a1dd",
   "metadata": {},
   "source": [
    "Import pandas and use it to store the data retrieved from the videos into a dataframe.\n",
    "Then print the dataframe for the benefit of the user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "113bf3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Total Number of Cars</th>\n",
       "      <th>Cars per Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Traffic_Laramie_1.mp4</td>\n",
       "      <td>6</td>\n",
       "      <td>2.023381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic_Laramie_2.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.271007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Total Number of Cars  Cars per Minute\n",
       "0  Traffic_Laramie_1.mp4                     6         2.023381\n",
       "1  Traffic_Laramie_2.mp4                     4         2.271007"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = [[\"Traffic_Laramie_1.mp4\", city_center1, city_center1 / length1], [\"Traffic_Laramie_2.mp4\", city_center2, city_center2 / length2]]\n",
    "pd.DataFrame(data, columns=[\"\", \"Total Number of Cars\", \"Cars per Minute\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f84aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb2d7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
